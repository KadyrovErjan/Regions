{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i5KZmVfXlWlg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchaudio import datasets, transforms, info, load\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import os\n",
        "import zipfile\n",
        "import torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/Regions.zip', 'r') as zip:\n",
        "    zip.extractall('.')"
      ],
      "metadata": {
        "id": "50wQrooglgEW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path_train = '/content/Regions/train'\n",
        "data_path_test = '/content/Regions/test'"
      ],
      "metadata": {
        "id": "23p3Umllfv6k"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKYI0N8pd2D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = sorted(os.listdir(data_path_train))\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYI_AGire9-n",
        "outputId": "61a8cd72-dc18-4384-a20f-5bc6f25eea43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alay',\n",
              " 'batken',\n",
              " 'bishkek',\n",
              " 'chui',\n",
              " 'jalal-abad',\n",
              " 'manas',\n",
              " 'naryn',\n",
              " 'osh',\n",
              " 'talas',\n",
              " 'ysyk-kol']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_index = {lab: ind for ind, lab in enumerate(labels)}\n",
        "label_to_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7m09nk9lgHf",
        "outputId": "6818e1aa-8890-4c9d-a332-6233c5727798"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alay': 0,\n",
              " 'batken': 1,\n",
              " 'bishkek': 2,\n",
              " 'chui': 3,\n",
              " 'jalal-abad': 4,\n",
              " 'manas': 5,\n",
              " 'naryn': 6,\n",
              " 'osh': 7,\n",
              " 'talas': 8,\n",
              " 'ysyk-kol': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.MelSpectrogram(\n",
        "    sample_rate=16000,\n",
        "    n_fft=1024,           # большее окно → лучше частотное разрешение\n",
        "    win_length=1024,\n",
        "    hop_length=256,       # меньшее смещение → лучше временное разрешение\n",
        "    n_mels=64,\n",
        "    f_min=0,              # можно обрезать низкие частоты, если шум\n",
        "    f_max=8000,           # ограничить до Nyquist частоты (sample_rate / 2)\n",
        "    power=2.0             # энергия спектра, можно 1.0 для амплитуды\n",
        ")"
      ],
      "metadata": {
        "id": "bU1jBg6YlgLM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 500"
      ],
      "metadata": {
        "id": "Ug37iYb1itb9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    spectrograms, targets = [], []\n",
        "    for file_path, label in batch:\n",
        "        waveform, sr = torchaudio.load(file_path)\n",
        "\n",
        "        # моно\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "        # ресемплинг\n",
        "        if sr != 16000:\n",
        "            waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n",
        "\n",
        "        spec = transform(waveform).squeeze()\n",
        "\n",
        "        # паддинг или обрезание\n",
        "        if spec.shape[1] > max_len:\n",
        "            spec = spec[:, :max_len]\n",
        "        elif spec.shape[1] < max_len:\n",
        "            pad_amount = max_len - spec.shape[1]\n",
        "            spec = F.pad(spec, (0, pad_amount))\n",
        "\n",
        "        spectrograms.append(spec)\n",
        "        targets.append(label_to_index[label])\n",
        "\n",
        "    spectrograms = torch.stack(spectrograms)\n",
        "    targets = torch.tensor(targets)\n",
        "    return spectrograms, targets"
      ],
      "metadata": {
        "id": "a_dRbg4hlgOZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.labels = sorted(os.listdir(data_path))\n",
        "        self.label_to_index = {lab: ind for ind, lab in enumerate(self.labels)}\n",
        "\n",
        "        for label in self.labels:\n",
        "            label_folder = os.path.join(data_path, label)\n",
        "            for file in os.listdir(label_folder):\n",
        "                if file.endswith('.wav'):  # или другой формат аудио\n",
        "                    self.data.append((os.path.join(label_folder, file), label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "id": "QQxwEeHfefh9"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4A7NpT2hhEU",
        "outputId": "2227e74f-e0aa-46f8-b4f3-87e9d82756cf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = AudioDataset(data_path_train, transform=transform)\n",
        "test_dataset = AudioDataset(data_path_test, transform=transform)"
      ],
      "metadata": {
        "id": "DcwoYvlglgRO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "test = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "L7cKJD5Leo2H"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "bFGthAiQlgUk"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlaceAudio(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(PlaceAudio, self).__init__()\n",
        "        self.first = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d((8, 8))\n",
        "        )\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.second = nn.Sequential(\n",
        "            nn.Linear(64 * 8 * 8, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.first(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.second(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Qsr5_QN1lgXi"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PlaceAudio().to(device)"
      ],
      "metadata": {
        "id": "zv8tGsSblga4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "mzkYPAu-lgek"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for x_batch, y_batch in train:\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "    y_pred = model(x_batch)\n",
        "    loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "  print(f'Эпоха {epoch+1}, Потери: {total_loss}')"
      ],
      "metadata": {
        "id": "fbXt2kyzlghq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f93813-17ca-4ed2-cde1-a63fe002ec94"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1, Потери: 0.35440122449290357\n",
            "Эпоха 2, Потери: 0.34267239795372006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        y_pred = model(x_batch)\n",
        "        pred = torch.argmax(y_pred, dim=1)\n",
        "\n",
        "        total += y_batch.size(0)\n",
        "        correct += (pred == y_batch).sum().item()\n",
        "\n",
        "accuracy = correct * 100 / total\n",
        "print(f'точность модели : {accuracy :.2f}%')"
      ],
      "metadata": {
        "id": "RxArcUD7lglA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10dee2e-f2f6-49af-e1de-885aec58dc99"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "точность модели : 93.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'region_model.pth')\n"
      ],
      "metadata": {
        "id": "ZpqYkWlslgn6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(labels,'region_labels.pth')"
      ],
      "metadata": {
        "id": "Zsd2H_hLlgrE"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TAzpsywTlguW"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kzEGwGuBlgx_"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0GS-Kblxlg1i"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGcpLnfplg5B"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XHKGwk8Wlg9p"
      },
      "execution_count": 88,
      "outputs": []
    }
  ]
}